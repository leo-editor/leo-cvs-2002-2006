<?xml version="1.0" encoding="UTF-8"?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="5056" clone_windows="0"/>
<globals body_outline_ratio="0.472807991121">
	<global_window_position top="25" left="385" height="901" width="840"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences>
</preferences>
<find_panel_settings>
	<find_string></find_string>
	<change_string></change_string>
</find_panel_settings>
<vnodes>
<v t="EKR.20040519090151"><vh>Diary</vh>
<v t="ekr.20031218072017"><vh>@thin ../doc/leoDiary.txt</vh></v>
</v>
<v t="EKR.20040430162943"><vh>Notes</vh>
<v t="ekr.20031218072017.329"><vh>@thin ../doc/leoNotes.txt</vh></v>
</v>
<v t="EKR.20040519090151.3"><vh>Projects</vh>
<v t="EKR.20040429143933"
marks="ekr.20031218072017.2772,ekr.20031218072017.2772,ekr.20031218072017.2772,ekr.20031218072017.2772,ekr.20031218072017.2772,ekr.20031218072017.2772,ekr.20040711135244.10,"><vh>@thin leoProjects.txt</vh></v>
</v>
<v t="EKR.20040519090151.2"><vh>To do</vh>
<v t="ekr.20040117181936"><vh>@thin ../doc/leoToDo.txt</vh></v>
</v>
<v t="ekr.20031218072017.2406"><vh>Code</vh>
<v t="ekr.20031218072017.2582" a="M"><vh> version &amp; signon stuff</vh>
<v t="ekr.20040629121554"><vh>getBuildNumber</vh></v>
<v t="ekr.20040629121554.1"><vh>getSignOnLine</vh></v>
<v t="ekr.20040629121554.2" a="M"><vh>initVersion</vh></v>
<v t="ekr.20040629121554.3"><vh>signOnWithVersion</vh></v>
</v>
<v t="ekr.20031218072017.2415"><vh> Scripts</vh>
<v t="ekr.20040327103735.2"><vh>Script Tools (leoGlobals.py)</vh>
<v t="ekr.20031218072017.2418"><vh>g.initScriptFind (set up dialog)</vh></v>
<v t="ekr.20040321065415"><vh>g.findNodeInTree, findNodeAnywhere, findTopLevelNode</vh></v>
</v>
<v t="EKR.20040502195524"><vh>@thin ../scripts/leoScripts.txt</vh></v>
<v t="EKR.20040502194930"><vh>@thin ../scripts/tangle_done.py</vh></v>
<v t="ekr.20031218072017.2537"><vh>@thin ../scripts/untangle_done.py</vh></v>
</v>
<v t="ekr.20031218072017.2604"><vh>Core classes...</vh>
<v t="ekr.20031218072017.2605"><vh>@thin leo.py </vh></v>
<v t="ekr.20031218072017.2608"><vh>@thin leoApp.py</vh></v>
<v t="ekr.20031218072017.2794"><vh>@thin leoColor.py</vh></v>
<v t="ekr.20031218072017.2810"
marks="ekr.20031218072017.2582,ekr.20040629121554.2,ekr.20040711135244.10,"><vh>@thin leoCommands.py</vh></v>
<v t="ekr.20031218072017.3001"><vh>@thin leoConfig.py</vh></v>
<v t="ekr.20031218072017.3052"><vh>@thin leoFind.py</vh></v>
<v t="ekr.20031218072017.3749"><vh>@thin leoMenu.py</vh></v>
<v t="ekr.20031218072017.3439"><vh>@thin leoPlugins.py</vh></v>
<v t="ekr.20031218072017.3446"><vh>@thin leoTangle.py</vh></v>
<v t="ekr.20031218072017.3603"><vh>@thin leoUndo.py</vh></v>
</v>
<v t="ekr.20031218072017.3625"><vh>Gui Base classes</vh>
<v t="ekr.20031218072017.3626"><vh>@thin leoColorPanel.py</vh></v>
<v t="ekr.20031218072017.3630"><vh>@thin leoCompare.py</vh></v>
<v t="ekr.20031218072017.3652"><vh>@thin leoFontPanel.py</vh></v>
<v t="ekr.20031218072017.3655"><vh>@thin leoFrame.py</vh></v>
<v t="ekr.20031218072017.3719"><vh>@thin leoGui.py</vh></v>
<v t="ekr.20031218072017.3748"><vh>@thin leoKeys.py</vh></v>
<v t="ekr.20031218072017.3812"><vh>@thin leoPrefs.py</vh></v>
</v>
<v t="ekr.20031218072017.3821"><vh>Gui Tkinter classes</vh>
<v t="ekr.20031218072017.3822"><vh>@thin leoTkinterColorPanels.py</vh></v>
<v t="ekr.20031218072017.3838"><vh>@thin leoTkinterComparePanel.py</vh></v>
<v t="ekr.20031218072017.3858"><vh>@thin leoTkinterDialog.py</vh></v>
<v t="ekr.20031218072017.3897"><vh>@thin leoTkinterFind.py</vh></v>
<v t="ekr.20031218072017.3909"><vh>@thin leoTkinterFontPanel.py</vh></v>
<v t="ekr.20031218072017.3939"><vh>@thin leoTkinterFrame.py</vh></v>
<v t="ekr.20031218072017.4047"><vh>@thin leoTkinterGui.py</vh></v>
<v t="ekr.20031218072017.4099"><vh>@thin leoTkinterKeys.py</vh></v>
<v t="ekr.20031218072017.4100"><vh>@thin leoTkinterMenu.py</vh></v>
<v t="ekr.20031218072017.4122"><vh>@thin leoTkinterPrefs.py</vh></v>
</v>
<v t="EKR.20040503105354.1"><vh>Active</vh>
<v t="ekr.20031218072017.2620"
marks="ekr.20031218072017.2772,"><vh>@thin leoAtFile.py </vh></v>
<v t="ekr.20031218072017.3018"><vh>@thin leoFileCommands.py</vh></v>
<v t="ekr.20031218072017.3093"
marks="ekr.20040718101315,"><vh>@thin leoGlobals.py</vh></v>
<v t="ekr.20031218072017.3206"
marks="ekr.20040717113036,"><vh>@thin leoImport.py</vh></v>
<v t="ekr.20031218072017.3320"><vh>@thin leoNodes.py</vh></v>
<v t="ekr.20031218072017.4138"><vh>@thin leoTkinterTree.py</vh></v>
</v>
</v>
<v t="EKR.20040506075328.3" a="E"><vh>(Perfect Import)</vh>
<v t="EKR.20040505103527" a="TV"><vh>To do</vh>
<v t="ekr.20040718050922"><vh>Add options to handle under-indent blanks lines</vh></v>
</v>
<v t="ekr.20040717133553"><vh>What I did</vh></v>
<v t="ekr.20040716105102.1"><vh>(Fixed bugs with handling @nonl)</vh>
<v t="EKR.20040505080156.2"><vh>removeSentinelsFromFile/Lines</vh>
<v t="ekr.20040716105102"><vh>&lt;&lt; remove the newline from result[-1] if line[i] is followed by @nonl &gt;&gt;</vh></v>
</v>
<v t="EKR.20040504150046.6"><vh>create_mapping</vh></v>
</v>
<v t="ekr.20040718042049"><vh>From atFile...</vh>
<v t="ekr.20031218072017.2756"><vh>Reading (4.x)</vh>
<v t="ekr.20040321064134.5"><vh>createThinChild (4.2)</vh></v>
<v t="ekr.20031218072017.2757"><vh>new_df.readOpenFile</vh></v>
<v t="ekr.20031218072017.2007"><vh>findChild 4.x</vh>
<v t="ekr.20040716061450"><vh>&lt;&lt; Check the headlines &gt;&gt;</vh></v>
</v>
<v t="ekr.20031218072017.2758"><vh>scanText4 &amp; allies</vh>
<v t="ekr.20031218072017.2759"><vh>&lt;&lt; init ivars for scanText4 &gt;&gt;</vh></v>
<v t="ekr.20031218072017.2760"><vh>&lt;&lt; report unexpected end of text &gt;&gt;</vh></v>
<v t="ekr.20031218072017.2761"><vh>readNormalLine</vh>
<v t="ekr.20031218072017.2762"><vh>&lt;&lt; Skip the leading stuff &gt;&gt;</vh></v>
<v t="ekr.20031218072017.2763"><vh>&lt;&lt; Append s to docOut &gt;&gt;</vh></v>
</v>
<v t="ekr.20031218072017.2764"><vh>start sentinels</vh>
<v t="EKR.20040430081719"><vh>readStartAll (4.2)</vh></v>
<v t="ekr.20031218072017.1752"><vh>readStartAt &amp; readStartDoc</vh></v>
<v t="ekr.20031218072017.2765"><vh>readStartLeo</vh></v>
<v t="EKR.20040524070500"><vh>readStartMiddle</vh></v>
<v t="ekr.20031218072017.2766"><vh>readStartNode</vh>
<v t="EKR.20040427105350"><vh>&lt;&lt; set gnx and bump i &gt;&gt;</vh></v>
<v t="ekr.20031218072017.2767"><vh>&lt;&lt; Set headline, undoing the CWEB hack &gt;&gt;</vh></v>
<v t="ekr.20031218072017.2768"><vh>&lt;&lt; Check the filename in the sentinel &gt;&gt;</vh></v>
</v>
<v t="ekr.20031218072017.2769"><vh>readStartOthers</vh></v>
</v>
<v t="ekr.20031218072017.2770"><vh>end sentinels</vh>
<v t="EKR.20040430081719.1"><vh>readEndAll (4.2)</vh></v>
<v t="ekr.20031218072017.1954"><vh>readEndAt &amp; readEndDoc</vh></v>
<v t="ekr.20031218072017.2771"><vh>readEndLeo</vh></v>
<v t="EKR.20040524071414"><vh>readEndMiddle</vh></v>
<v t="ekr.20031218072017.2772" a="M"><vh>readEndNode (4.x)</vh>
<v t="ekr.20040717133944"><vh>&lt;&lt; bump at.correctedLines and tell about the correction &gt;&gt;</vh></v>
</v>
<v t="ekr.20031218072017.2773"><vh>readEndOthers</vh></v>
<v t="ekr.20031218072017.1753"><vh>readLastDocLine</vh>
<v t="ekr.20031218072017.1754"><vh>&lt;&lt; new code &gt;&gt;</vh></v>
<v t="ekr.20031218072017.1755"><vh>&lt;&lt; old code &gt;&gt;</vh></v>
</v>
</v>
<v t="ekr.20031218072017.2774"><vh>Unpaired sentinels</vh>
<v t="ekr.20031218072017.2775"><vh>ignoreOldSentinel</vh></v>
<v t="ekr.20031218072017.2776"><vh>readAfterRef</vh></v>
<v t="EKR.20040520093903"><vh>readClone</vh></v>
<v t="ekr.20031218072017.2777"><vh>readComment</vh></v>
<v t="ekr.20031218072017.2778"><vh>readDelims</vh></v>
<v t="ekr.20031218072017.2779"><vh>readDirective</vh>
<v t="EKR.20040625104908"><vh>&lt;&lt; handle @language &gt;&gt;</vh></v>
<v t="EKR.20040625104908.1"><vh>&lt;&lt; handle @comment &gt;&gt;</vh></v>
</v>
<v t="ekr.20031218072017.2780"><vh>readNl</vh></v>
<v t="ekr.20031218072017.2781"><vh>readNonl</vh></v>
<v t="ekr.20031218072017.2782"><vh>readRef</vh></v>
<v t="ekr.20031218072017.2783"><vh>readVerbatim</vh></v>
</v>
<v t="ekr.20031218072017.2784"><vh>badEndSentinel, push/popSentinelStack</vh></v>
</v>
</v>
<v t="ekr.20031218072017.2114"><vh>new_df.write</vh>
<v t="ekr.20031218072017.2116"><vh>&lt;&lt; open the file; return on error &gt;&gt;</vh></v>
<v t="ekr.20031218072017.2121"><vh>&lt;&lt; set dirty and orphan bits on error &gt;&gt;</vh></v>
</v>
<v t="ekr.20031218072017.2757"><vh>new_df.readOpenFile</vh></v>
<v t="ekr.20031218072017.2772" a="M"><vh>readEndNode (4.x)</vh>
<v t="ekr.20040717133944"><vh>&lt;&lt; bump at.correctedLines and tell about the correction &gt;&gt;</vh></v>
</v>
</v>
<v t="ekr.20040718042049.1"><vh>From leoGlobals...</vh>
<v t="ekr.20040331083824.1"><vh>g.fileLikeObject</vh></v>
<v t="EKR.20040504150046"><vh>class mulderUpdateAlgorithm (leoGlobals)</vh>
<v t="EKR.20040504150046.3"><vh>__init__</vh></v>
<v t="EKR.20040504150046.9"><vh>copy_sentinels</vh></v>
<v t="EKR.20040504155109"><vh>copy_time</vh></v>
<v t="EKR.20040504150046.6"><vh>create_mapping</vh></v>
<v t="EKR.20040504154039"><vh>is_sentinel</vh></v>
<v t="EKR.20040504150046.4"><vh>marker_from_extension</vh></v>
<v t="EKR.20040505080156"><vh>Get or remove sentinel lines</vh>
<v t="EKR.20040505081121"><vh>separateSentinelsFromFile/Lines</vh></v>
<v t="EKR.20040505080156.2"><vh>removeSentinelsFromFile/Lines</vh>
<v t="ekr.20040716105102"><vh>&lt;&lt; remove the newline from result[-1] if line[i] is followed by @nonl &gt;&gt;</vh></v>
</v>
<v t="EKR.20040505080156.3"><vh>getSentinelsFromFile/Lines</vh></v>
</v>
<v t="EKR.20040504150046.10"><vh>propagateDiffsToSentinelsFile</vh>
<v t="EKR.20040504150046.11"><vh>&lt;&lt; init propagateDiffsToSentinelsFile vars &gt;&gt;</vh></v>
<v t="EKR.20040504150046.12"><vh>&lt;&lt;paranoia check&gt;&gt;</vh></v>
</v>
<v t="EKR.20040504145804.1"><vh>propagateDiffsToSentinelsLines (called from perfect import)</vh>
<v t="EKR.20040504145804.2"><vh>&lt;&lt; init propagateDiffsToSentinelsLines vars &gt;&gt;</vh></v>
<v t="EKR.20040504145804.3"><vh>&lt;&lt; copy the sentinels at the beginning of the file &gt;&gt;</vh></v>
<v t="EKR.20040504145804.4"><vh>&lt;&lt; update and check the loop invariant&gt;&gt;</vh></v>
<v t="EKR.20040504145804.5"><vh>&lt;&lt; handle 'equal' tag &gt;&gt;</vh></v>
<v t="EKR.20040504145804.6"><vh>&lt;&lt; handle 'replace' tag &gt;&gt;</vh></v>
<v t="EKR.20040504145804.7"><vh>&lt;&lt; handle 'delete' tag &gt;&gt;</vh></v>
<v t="EKR.20040504145804.8"><vh>&lt;&lt; handle 'insert' tag &gt;&gt;</vh></v>
<v t="EKR.20040504145804.9"><vh>&lt;&lt; copy the sentinels at the end of the file &gt;&gt;</vh></v>
</v>
<v t="EKR.20040504150046.5"><vh>report_mismatch</vh></v>
<v t="ekr.20040718101315" a="M"><vh>stripWhitespaceFromBlankLines(before_lines)</vh></v>
<v t="EKR.20040504160820"><vh>write_if_changed</vh>
<v t="EKR.20040504160820.1"><vh>&lt;&lt; make backup file &gt;&gt;</vh></v>
</v>
</v>
</v>
<v t="ekr.20031218072017.3212"><vh>importFilesCommand</vh>
<v t="ekr.20031218072017.3213"><vh>&lt;&lt; Create a parent for two files having a common prefix &gt;&gt;</vh></v>
</v>
<v t="EKR.20040506075328.2"><vh>perfectImport</vh>
<v t="ekr.20040717112739"><vh>&lt;&lt; about this algorithm &gt;&gt;</vh></v>
<v t="ekr.20040716065356"><vh>&lt;&lt; clear all dirty bits &gt;&gt;</vh></v>
<v t="ekr.20040716064333"><vh>&lt;&lt; Assign file indices  &gt;&gt;</vh></v>
<v t="ekr.20040716064333.1"><vh>&lt;&lt; Write root's tree to to string s &gt;&gt;</vh></v>
<v t="ekr.20040717132539"><vh>&lt;&lt; put the corrected fat lines in a new node &gt;&gt;</vh></v>
<v t="ekr.20040717113036" a="M"><vh>&lt;&lt; correct root's tree using write_lines &gt;&gt;</vh></v>
<v t="ekr.20040718035658"><vh>&lt;&lt; verify that writing the tree would produce the original file &gt;&gt;</vh>
<v t="ekr.20040718045423"><vh>&lt;&lt; dump the files &gt;&gt;</vh></v>
</v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="EKR.20040427105350"># We have skipped past the opening colon of the gnx.
j = s.find(':',i)
if j == -1:
    g.trace("no closing colon",g.get_line(s,i))
    at.readError("Expecting gnx in @+node sentinel")
    return # 5/17/04
else:
    gnx = s[i:j]
    i = j + 1 # Skip the i</t>
<t tx="EKR.20040430081719">def readStartAll (self,s,i):
    
    """Read an @+all sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert(g.match(s,j,"@+all"))
    else:
        assert(g.match(s,j,"+all"))

    # Make sure that the generated at-all is properly indented.
    at.out.append(leadingWs + "@all\n")
    
    at.endSentinelStack.append(endAll)</t>
<t tx="EKR.20040430081719.1">def readEndAll (self,s,i):
    
    """Read an @-all sentinel."""
    
    at = self
    at.popSentinelStack(endAll)</t>
<t tx="EKR.20040430162943"></t>
<t tx="EKR.20040503105354.1"></t>
<t tx="EKR.20040504145804.1">def propagateDiffsToSentinelsLines (self,
    i_lines,j_lines,fat_lines,mapping):
    
    """Compare the 'i_lines' with 'j_lines' and propagate the diffs back into
    'write_lines' making sure that all sentinels of 'fat_lines' are copied.

    i/j_lines have no sentinels.  fat_lines does."""

    &lt;&lt; init propagateDiffsToSentinelsLines vars &gt;&gt;
    &lt;&lt; copy the sentinels at the beginning of the file &gt;&gt;
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if testing:
            if verbose: print
            print "Opcode %7s %3d %3d %3d %3d" % (tag,i1,i2,j1,j2)
            if verbose: print
        &lt;&lt; update and check the loop invariant &gt;&gt;
        if tag == 'equal':
            &lt;&lt; handle 'equal' tag &gt;&gt;
        elif tag == 'replace':
            &lt;&lt; handle 'replace' tag &gt;&gt;
        elif tag == 'delete':
            &lt;&lt; handle 'delete' tag &gt;&gt;
        elif tag == 'insert':
            &lt;&lt; handle 'insert' tag &gt;&gt;
        else: assert 0,"bad tag"
    &lt;&lt; copy the sentinels at the end of the file &gt;&gt;
    return write_lines</t>
<t tx="EKR.20040504145804.2"># Indices into i_lines, j_lines &amp; fat_lines.
i_pos = j_pos = fat_pos = 0

# These vars check that all ranges returned by get_opcodes() are contiguous.
i2_old = j2_old = -1

# Create the output lines.
write_lines = []

matcher = difflib.SequenceMatcher(None,i_lines,j_lines)

testing = self.testing
verbose = self.verbose</t>
<t tx="EKR.20040504145804.3">while fat_pos &lt; mapping[0]:

    line = fat_lines[fat_pos]
    write_lines.append(line)
    if testing:
        print "copy initial line",fat_pos,line,
    fat_pos += 1
</t>
<t tx="EKR.20040504145804.4"># We need the ranges returned by get_opcodes to completely cover the source lines being compared.
# We also need the ranges not to overlap.

assert(i2_old in (-1,i1))
assert(j2_old in (-1,j1))

i2_old = i2 ; j2_old = j2

# Check the loop invariants.
assert i_pos == i1
assert j_pos == j1
assert fat_pos == mapping[i1]

if 0: # not yet.
    if testing: # A bit costly.
        t_sourcelines,t_sentinel_lines = push_filter_lines(write_lines, marker)
        # Check that we have all the modifications so far.
        assert t_sourcelines == j_lines[:j1],"t_sourcelines == j_lines[:j1]"
        # Check that we kept all sentinels so far.
        assert t_sentinel_lines == push_filter_lines(fat_lines[:fat_pos], marker)[1]</t>
<t tx="EKR.20040504145804.5"># Copy the lines, including sentinels.
while fat_pos &lt;= mapping[i2-1]:
    line = fat_lines[fat_pos]
    if 0: # too verbose.
        if testing: print "Equal: copying ", line,
    write_lines.append(line)
    fat_pos += 1

if testing and verbose:
    print "Equal: synch i", i_pos,i2
    print "Equal: synch j", j_pos,j2

i_pos = i2
j_pos = j2

# Copy the sentinels which might follow the lines.       
fat_pos = self.copy_sentinels(write_lines,fat_lines,fat_pos,mapping,i2-1,i2)</t>
<t tx="EKR.20040504145804.6">@ Replace lines that may span sentinels.

For now, we put all the new contents after the first sentinel.

A more complex approach: run the difflib across the different lines and try to
construct a mapping changed line =&gt; orignal line.
@c

while j_pos &lt; j2:
    line = j_lines[j_pos]
    if testing:
        print "Replace i:",i_pos,repr(i_lines[i_pos])
        print "Replace j:",j_pos,repr(line)
        i_pos += 1

    write_lines.append(line)
    j_pos += 1

i_pos = i2

# Copy the sentinels which might be between the changed code.         
fat_pos = self.copy_sentinels(write_lines,fat_lines,fat_pos,mapping,i1,i2)</t>
<t tx="EKR.20040504145804.7">if testing and verbose:
    print "delete: i",i_pos,i1
    print "delete: j",j_pos,j1

j_pos = j2
i_pos = i2

# Restore any deleted sentinels.
fat_pos = self.copy_sentinels(write_lines,fat_lines,fat_pos,mapping,i1,i2)</t>
<t tx="EKR.20040504145804.8">while j_pos &lt; j2:
    line = j_lines[j_pos]
    if testing: print "Insert:", line,
    write_lines.append(line)
    j_pos += 1

# The input streams are already in synch.</t>
<t tx="EKR.20040504145804.9">while fat_pos &lt; len(fat_lines):

    line = fat_lines[fat_pos]
    write_lines.append(line)
    if testing:
        print "Append last line",line
    fat_pos += 1
</t>
<t tx="EKR.20040504150046">import difflib,shutil

class mulderUpdateAlgorithm:
    
    """A class to update derived files using
    diffs in files without sentinels."""
    
    @others
    
def doMulderUpdateAlgorithm(sourcefilename,targetfilename):

    mu = mulderUpdateAlgorithm()

    mu.pull_source(sourcefilename,targetfilename)
    mu.copy_time(targetfilename,sourcefilename)</t>
<t tx="EKR.20040504150046.3">def __init__ (self,testing=False,verbose=False):
    
    self.testing = testing
    self.verbose = False
    self.do_backups = False</t>
<t tx="EKR.20040504150046.4">def marker_from_extension(self,filename):
    """
    Tries to guess the sentinel leadin
    comment from the filename extension.
    
    This code should probably be shared
    with the main Leo code.
    """
    root, ext = os.path.splitext(filename)
    if ext == '.tmp':
        root, ext = os.path.splitext(root)
    if ext in ('.h', '.c'):
        marker = "//@"
    elif ext in (".py", ".cfg", ".bat", ".ksh"):
        marker = "#@"
    else:
        g.trace("unknown extension %s" % ext)
        marker = None

    return marker</t>
<t tx="EKR.20040504150046.5">def report_mismatch (self,lines1,lines2,message,lines1_message,lines2_message):

    """
    Generate a report when something goes wrong.
    """

    print '='*20
    print message
    
    if 0:
        print lines1_message
        print '-'*20
        for line in lines1:
          print line,
         
        print '='*20
    
        print lines2_message
        print '-'*20
        for line in lines2:
            print line,</t>
<t tx="EKR.20040504150046.6">def create_mapping (self,lines,marker):
    """

    'lines' is a list of lines of a file with sentinels.
 
    Returns:

    result: lines with all sentinels removed.

    mapping: a list such that result[mapping[i]] == lines[i]
    for all i in range(len(result))

    """
    
    if not lines:
        return [],[]

    # Create mapping and set i to the index of the last non-sentinel line.
    mapping = []
    for i in xrange(len(lines)):
        if not self.is_sentinel(lines[i],marker):
            mapping.append(i)

    # Create a last mapping entry for copy_sentinels.
    mapping.append(i)
    
    # Use removeSentinelsFromLines to handle @nonl properly.
    stripped_lines = self.removeSentinelsFromLines(lines,marker)

    return stripped_lines, mapping</t>
<t tx="EKR.20040504150046.9">@ This script retains _all_ sentinels.  If lines are replaced, or deleted,
we restore deleted sentinel lines by checking for gaps in the mapping.
@c

def copy_sentinels (self,write_lines,fat_lines,fat_pos,mapping,startline,endline):
    """
    
    Copy sentinel lines from fat_lines to write_lines.

    Copy all sentinels _after_ the current reader postion up to,
    but not including, mapping[endline].

    """

    j_last = mapping[startline]
    i = startline + 1
    while i &lt;= endline:
        j = mapping[i]
        if j_last + 1 != j:
            fat_pos = j_last + 1
            # Copy the deleted sentinels that comprise the gap.
            while fat_pos &lt; j:
                line = fat_lines[fat_pos]
                write_lines.append(line)
                if self.testing and self.verbose: print "Copy sentinel:",fat_pos,line,
                fat_pos += 1
        j_last = j ; i += 1

    fat_pos = mapping[endline]
    return fat_pos</t>
<t tx="EKR.20040504150046.10">def propagateDiffsToSentinelsFile(self,sourcefilename,targetfilename):
    
    &lt;&lt; init propagateDiffsToSentinelsFile vars &gt;&gt;
    
    write_lines = self.propagateDiffsToSentinelsLines(
        i_lines,j_lines,fat_lines,mapping)
        
    # Update _source_ file if it is not the same as write_lines.
    written = self.write_if_changed(write_lines,targetfilename,sourcefilename)
    if written:
        &lt;&lt; paranoia check&gt;&gt;</t>
<t tx="EKR.20040504150046.11"># Get the sentinel comment marker.
marker = self.marker_from_extension(sourcefilename)
if not marker:
    return

try:
    # Create the readers.
    sfile = file(sourcefilename)
    tfile = file(targetfilename)
    
    fat_lines = sfile.readlines() # Contains sentinels.
    j_lines   = tfile.readlines() # No sentinels.
    
    i_lines,mapping = self.create_mapping(fat_lines,marker)
    
    sfile.close()
    tfile.close()
except:
    g.es_exception("can not open files")
    return</t>
<t tx="EKR.20040504150046.12"># Check that 'push' will re-create the changed file.
strippedLines,sentinel_lines = self.separateSentinelsFromFile(sourcefilename)

if strippedLines != j_lines:
    self.report_mismatch(strippedLines, j_lines,
        "Propagating diffs did not work as expected",
        "Content of sourcefile:",
        "Content of modified file:")

# Check that no sentinels got lost.
fat_sentinel_lines = self.getSentinelsFromLines(fat_lines,marker)

if sentinel_lines != fat_sentinel_lines:
    self.report_mismatch(sentinel_lines,fat_sentinel_lines,
        "Propagating diffs modified sentinel lines:",
        "Current sentinel lines:",
        "Old sentinel lines:")</t>
<t tx="EKR.20040504154039">def is_sentinel (self,line,marker):
    
    """
    Check if line starts with a sentinel comment.
    """
    
    return line.lstrip().startswith(marker)
</t>
<t tx="EKR.20040504155109">def copy_time(self,sourcefilename,targetfilename):
    
    """
    Set the target file's modification time to
    that of the source file.
    """

    st = os.stat(sourcefilename)

    if hasattr(os, 'utime'):
        os.utime(targetfilename, (st.st_atime, st.st_mtime))
    elif hasattr(os, 'mtime'):
        os.mtime(targetfilename, st.st_mtime)
    else:
        g.trace("Can not set modification time")</t>
<t tx="EKR.20040504160820">def write_if_changed(self,lines,sourcefilename,targetfilename):
    """
    
    Replaces target file if it is not the same as 'lines',
    and makes the modification date of target file the same as the source file.
    
    Optionally backs up the overwritten file.

    """
    
    copy = not os.path.exists(targetfilename) or lines != file(targetfilename).readlines()
        
    if self.testing:
        if copy:
            print "Writing",targetfilename,"without sentinals"
        else:
            print "Files are identical"

    if copy:
        if self.do_backups:
            &lt;&lt; make backup file &gt;&gt;
        outfile = open(targetfilename, "w")
        for line in lines:
            outfile.write(line)
        outfile.close()
        self.copy_time(sourcefilename,targetfilename)
    return copy
</t>
<t tx="EKR.20040504160820.1">if os.path.exists(targetfilename):
    count = 0
    backupname = "%s.~%s~" % (targetfilename,count)
    while os.path.exists(backupname):
        count += 1
        backupname = "%s.~%s~" % (targetfilename,count)
    os.rename(targetfilename, backupname)
    if testing:
        print "backup file in ", backupname</t>
<t tx="EKR.20040505080156"># These routines originally were part of push_filter &amp; push_filter_lines.</t>
<t tx="EKR.20040505080156.2">def removeSentinelsFromFile (self,filename):
    
    """Return a copy of file with all sentinels removed."""
    
    lines = file(filename).readlines()
    marker = self.marker_from_extension(filename)
    
    return removeSentinelsFromLines(lines,marker)
    
def removeSentinelsFromLines (self,lines,marker):

    """Return a copy of lines with all sentinels removed."""
    
    if 0: # Doesn't handle trailing @nonl properly.
        return [line for line in lines if not self.is_sentinel(line,marker)]
    else:
        result = [] ; last_nosent_i = -1
        for i in xrange(len(lines)):
            if not self.is_sentinel(lines[i],marker):
                result.append(lines[i])
                last_nosent_i = i
        &lt;&lt; remove the newline from result[-1] if line[i] is followed by @nonl &gt;&gt;
        return result</t>
<t tx="EKR.20040505080156.3">def getSentinelsFromFile (self,filename,marker):
    
    """Returns all sentinels lines in a file."""
    
    lines = file(filename).readlines()
    marker = self.marker_from_extension(filename)

    return getSentinelsFromLines(lines,marker)
    
def getSentinelsFromLines (self,lines,marker):
    
    """Returns all sentinels lines in lines."""
    
    return [line for line in lines if self.is_sentinel(line,marker)]</t>
<t tx="EKR.20040505081121">def separateSentinelsFromFile (self,filename):
    
    """Separate the lines of the file into a tuple of two lists,
    containing the sentinel and non-sentinel lines of the file."""
    
    lines = file(filename).readlines()
    marker = self.marker_from_extension(filename)
    
    return self.separateSentinelsFromLines(lines,marker)
    
def separateSentinelsFromLines (self,lines,marker):
    
    """Separate lines (a list of lines) into a tuple of two lists,
    containing the sentinel and non-sentinel lines of the original list."""
    
    strippedLines = self.removeSentinelsFromLines(lines,marker)
    sentinelLines = self.getSentinelsFromLines(lines,marker)
    
    return strippedLines,sentinelLines</t>
<t tx="EKR.20040505103527">@killcolor

- Make mu.is_sentinel correct in all situations: use atFile function.

- Replace mu.arker_from_extension with a function in leoGlobals.py.
</t>
<t tx="EKR.20040506075328.2">def perfectImport (self,fileName,p,testing=False,verbose=False,convertBlankLines=True,verify=True):
    
    &lt;&lt; about this algorithm &gt;&gt;
    c = p.c ; root = p.copy()
    df = c.atFileCommands.new_df
    if testing:
        &lt;&lt; clear all dirty bits &gt;&gt;
    &lt;&lt; Assign file indices &gt;&gt;
    &lt;&lt; Write root's tree to to string s &gt;&gt;

    # Set up the data for the algorithm.
    mu = g.mulderUpdateAlgorithm(testing=testing,verbose=verbose)
    marker = mu.marker_from_extension(fileName)
    fat_lines = g.splitLines(s) # Keep the line endings.
    i_lines,mapping = mu.create_mapping(fat_lines,marker)
    j_lines = file(fileName).readlines()
    
    # Correct write_lines using the algorihm.
    if i_lines != j_lines:
        if verbose:
            g.es("Running Perfect Import",color="blue")
        write_lines = mu.propagateDiffsToSentinelsLines(i_lines,j_lines,fat_lines,mapping)
        if 0: # For testing.
            &lt;&lt; put the corrected fat lines in a new node &gt;&gt;
        &lt;&lt; correct root's tree using write_lines &gt;&gt;
    if verify:
        &lt;&lt; verify that writing the tree would produce the original file &gt;&gt;</t>
<t tx="EKR.20040506075328.3"></t>
<t tx="EKR.20040519090151"></t>
<t tx="EKR.20040519090151.2"></t>
<t tx="EKR.20040519090151.3"></t>
<t tx="EKR.20040520093903">def readClone (self,s,i):
    
    at = self ; tag = "clone"

    assert(g.match(s,i,tag))
    
    # Skip the tag and whitespace.
    i = g.skip_ws(s,i+len(tag))
    
    # Get the clone count.
    junk,val = g.skip_long(s,i)
    
    if val == None:
        at.readError("Invalid count in @clone sentinel")
    else:
        at.cloneSibCount	 = val</t>
<t tx="EKR.20040524070500">def readStartMiddle (self,s,i):
    
    """Read an @+middle sentinel."""
    
    at = self
    
    at.readStartNode(s,i,middle=True)</t>
<t tx="EKR.20040524071414">def readEndMiddle (self,s,i):
    
    """Read an @-middle sentinel."""
    
    at = self
    
    at.readEndNode(s,i,middle=True)</t>
<t tx="EKR.20040625104908"># Skip the keyword and whitespace.
i += len("@language")
i = g.skip_ws(s,i)
j = g.skip_c_id(s,i)
language = s[i:j]

delim1,delim2,delim3 = g.set_delims_from_language(language)

#g.trace(g.get_line(s,i))
#g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    at.startSentinelComment = delim1
    at.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    at.startSentinelComment = delim2
    at.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("Ignoring bad @@language sentinel: %s" % line,color="red")</t>
<t tx="EKR.20040625104908.1">j = g.skip_line(s,i)
line = s[i:j]
delim1,delim2,delim3 = g.set_delims_from_string(line)

#g.trace(g.get_line(s,i))
#g.trace(delim1,delim2,delim3)

# Returns a tuple (single,start,end) of comment delims
if delim1:
    self.startSentinelComment = delim1
    self.endSentinelComment = "" # Must not be None.
elif delim2 and delim3:
    self.startSentinelComment = delim2
    self.endSentinelComment = delim3
else:
    line = g.get_line(s,i)
    g.es("Ignoring bad @comment sentinel: %s" % line,color="red")</t>
<t tx="ekr.20031218072017.1752">def readStartAt (self,s,i):
    """Read an @+at sentinel."""
    at = self ; assert(g.match(s,i,"+at"))
    if 0:# new code: append whatever follows the sentinel.
        i += 3 ; j = self.skipToEndSentinel(s,i) ; follow = s[i:j]
        at.out.append('@' + follow) ; at.docOut = []
    else:
        i += 3 ; j = g.skip_ws(s,i) ; ws = s[i:j]
        at.docOut = ['@' + ws + '\n'] # This newline may be removed by a following @nonl
    at.inCode = False
    at.endSentinelStack.append(endAt)
    
def readStartDoc (self,s,i):
    """Read an @+doc sentinel."""
    at = self ; assert(g.match(s,i,"+doc"))
    if 0: # new code: append whatever follows the sentinel.
        i += 4 ; j = self.skipToEndSentinel(s,i) ; follow = s[i:j]
        at.out.append('@' + follow) ; at.docOut = []
    else:
        i += 4 ; j = g.skip_ws(s,i) ; ws = s[i:j]
        at.docOut = ["@doc" + ws + '\n'] # This newline may be removed by a following @nonl
    at.inCode = False
    at.endSentinelStack.append(endDoc)
    
def skipToEndSentinel(self,s,i):
    end = self.endSentinelComment
    if end:
        j = s.find(end,i)
        if j == -1:
            return g.skip_to_end_of_line(s,i)
        else:
            return j
    else:
        return g.skip_to_end_of_line(s,i)</t>
<t tx="ekr.20031218072017.1753">def readLastDocLine (self,tag):
    
    """Read the @c line that terminates the doc part.
    tag is @doc or @."""
    
    at = self
    end = at.endSentinelComment
    start = at.startSentinelComment
    s = ''.join(at.docOut)
    
    if 0: # new code.
        &lt;&lt; new code &gt;&gt;
    else:
        &lt;&lt; old code &gt;&gt;</t>
<t tx="ekr.20031218072017.1754">if end:
    # Remove opening block delim.
    if g.match(s,0,start):
        s = s[len(start):]
    else:
        at.readError("Missing open block comment")
        g.trace(s)
        return
        
    # Remove trailing newline.
    if s[-1] == '\n':
        s = s[:-1]

    # Remove closing block delim.
    if s[-len(end):] == end:
        s = s[:-len(end)]
    else:
        at.readError("Missing close block comment")
        return

at.out.append(s) # The tag has already been removed.
at.docOut = []</t>
<t tx="ekr.20031218072017.1755"># Remove the @doc or @space.  We'll add it back at the end.
if g.match(s,0,tag):
    s = s[len(tag):]
else:
    at.readError("Missing start of doc part")
    return

if end:
    # Remove opening block delim.
    if g.match(s,0,start):
        s = s[len(start):]
    else:
        at.readError("Missing open block comment")
        g.trace(s)
        return
        
    # Remove trailing newline.
    if s[-1] == '\n':
        s = s[:-1]

    # Remove closing block delim.
    if s[-len(end):] == end:
        s = s[:-len(end)]
    else:
        at.readError("Missing close block comment")
        return

at.out.append(tag + s)
at.docOut = []</t>
<t tx="ekr.20031218072017.1954">def readEndAt (self,s,i):
    
    """Read an @-at sentinel."""

    at = self
    at.readLastDocLine("@")
    at.popSentinelStack(endAt)
    at.inCode = True
        
def readEndDoc (self,s,i):
    
    """Read an @-doc sentinel."""

    at = self
    at.readLastDocLine("@doc")
    at.popSentinelStack(endDoc)
    at.inCode = True</t>
<t tx="ekr.20031218072017.2007">def findChild (self,headline):
    
    """Return the next tnode in at.root.t.tnodeList."""

    at = self ; v = at.root.v

    if not hasattr(v.t,"tnodeList"):
        at.readError("no tnodeList for " + repr(v))
        g.es("Write the @file node or use the Import Derived File command")
        g.trace("no tnodeList for ",v)
        return None
        
    if at.tnodeListIndex &gt;= len(v.t.tnodeList):
        at.readError("bad tnodeList index: %d, %s" % (at.tnodeListIndex,repr(v)))
        g.trace("bad tnodeList index",at.tnodeListIndex,len(v.t.tnodeList),v)
        return None
        
    t = v.t.tnodeList[at.tnodeListIndex]
    assert(t)
    at.tnodeListIndex += 1

    # Get any vnode joined to t.
    try:
        v = t.vnodeList[0]
    except:
        at.readError("No vnodeList for tnode: %s" % repr(t))
        g.trace(at.tnodeListIndex)
        return None
        
    # Don't check the headline.  It simply causes problems.
    t.setVisited() # Supress warning about unvisited node.
    return t
    
    if 0: # Old code:
        &lt;&lt; Check the headlines &gt;&gt;</t>
<t tx="ekr.20031218072017.2114"># This is the entry point to the write code.  root should be an @file vnode.

def write(self,root,nosentinels=False,thinFile=False,toString=False,oneNodeOnly=False):
    
    """Write a 4.x derived file."""
    
    at = self ; c = at.c

    &lt;&lt; open the file; return on error &gt;&gt;
    try:
        self.writeOpenFile(root,nosentinels,thinFile,toString,oneNodeOnly)
        if toString:
            at.closeWriteFile()
            # Major bug: failure to clear this wipes out headlines!
            # Minor bug: sometimes this causes slight problems...
            at.root.v.t.tnodeList = [] 
        else:
            at.closeWriteFile()
            &lt;&lt; set dirty and orphan bits on error &gt;&gt;
    except:
        if toString:
            g.es("exception preprocessing script",color="blue")
            g.es_exception(full=False)
            at.root.v.t.tnodeList = []
        else:
            at.handleWriteException() # Sets dirty and orphan bits.</t>
<t tx="ekr.20031218072017.2116">if toString:
    at.targetFileName = "&lt;new_df.write string-file&gt;"
elif nosentinels:
    at.targetFileName = root.atNoSentFileNodeName()
elif thinFile:
    at.targetFileName = root.atThinFileNodeName()
else:
    at.targetFileName = root.atFileNodeName()
    
ok = at.openWriteFile(root,toString)
    
if not ok:
    return</t>
<t tx="ekr.20031218072017.2121"># Setting the orphan and dirty flags tells Leo to write the tree..

if at.errors &gt; 0 or at.root.isOrphan():
    root.setOrphan()
    root.setDirty() # Make _sure_ we try to rewrite this file.
    os.remove(at.outputFileName) # Delete the temp file.
    g.es("Not written: " + at.outputFileName)
else:
    root.clearOrphan()
    root.clearDirty()
    at.replaceTargetFileIfDifferent()</t>
<t tx="ekr.20031218072017.2406">@language python
@tabwidth -4
@pagewidth 80

@ This section contains all the source code of leo.py.

Leo's code uses the following conventions throughout:

c:  a commander
ch: a character
d:  a dialog or a dict.
g:  the leoGlobal module.
i, j, k: indices into a string
lst: a list (Do _not_ use list, it is a Python global!)
p:  a position.
s:  a string
t:  a tnode or a text widget.
u:  an undoer
v:  a vnode

See the child of this node called "Overview of Code" for more documentation.</t>
<t tx="ekr.20031218072017.2415"></t>
<t tx="ekr.20031218072017.2418">def initScriptFind(findHeadline,changeHeadline=None,firstNode=None,
    script_search=True,script_change=True):
    
    import leoTest
    import leoGlobals as g
    
    # Find the scripts.
    c = g.top() ; p = c.currentPosition()
    u = leoTest.testUtils()
    find_p = u.findNodeInTree(p,findHeadline)
    if find_p:
        find_text = find_p.bodyString()
    else:
        g.es("no Find script node",color="red")
        return
    if changeHeadline:
        change_p = u.findNodeInTree(p,changeHeadline)
    else:
        change_p = None
    if change_p:
        change_text = change_p.bodyString()
    else:
        change_text = ""
    # print find_p,change_p
    
    # Initialize the find panel.
    c.script_search_flag = script_search
    c.script_change_flag = script_change and change_text
    if script_search:
        c.find_text = find_text.strip() + "\n"
    else:
        c.find_text = find_text
    if script_change:
        c.change_text = change_text.strip() + "\n"
    else:
        c.change_text = change_text
    g.app.findFrame.init(c)
    c.findPanel()</t>
<t tx="ekr.20031218072017.2582"></t>
<t tx="ekr.20031218072017.2604"></t>
<t tx="ekr.20031218072017.2756"></t>
<t tx="ekr.20031218072017.2757">def readOpenFile(self,root,file,firstLines,perfectImportRoot=None):
    
    """Read an open 4.x thick or thin derived file."""
    
    at = self
    
    # This is safe (just barely) because only this method calls scanText4&gt;
    at.perfectImportRoot = perfectImportRoot

    # Scan the 4.x file.
    at.tnodeListIndex = 0
    # at.thinFile tells scanText4 whether this is a thin file or not.
    lastLines = at.scanText4(file,root)
    root.v.t.setVisited() # Disable warning about set nodes.
    
    # Handle first and last lines.
    try: body = root.v.t.tempBodyString
    except: body = ""
    lines = body.split('\n')
    at.completeFirstDirectives(lines,firstLines)
    at.completeLastDirectives(lines,lastLines)
    s = '\n'.join(lines).replace('\r', '')
    root.v.t.tempBodyString = s</t>
<t tx="ekr.20031218072017.2758">def scanText4 (self,file,p):
    
    """Scan a 4.x derived file non-recursively."""

    at = self
    &lt;&lt; init ivars for scanText4 &gt;&gt;
    while at.errors == 0 and not at.done:
        s = at.readLine(file)
        if len(s) == 0: break
        kind = at.sentinelKind(s)
        # g.trace(at.sentinelName(kind),s.strip())
        if kind == noSentinel:
            i = 0
        else:
            i = at.skipSentinelStart(s,0)
        func = at.dispatch_dict[kind]
        func(s,i)

    if at.errors == 0 and not at.done:
        &lt;&lt; report unexpected end of text &gt;&gt;

    return at.lastLines
</t>
<t tx="ekr.20031218072017.2759"># Unstacked ivars...
at.cloneSibCount = 0
at.done = False
at.inCode = True
at.indent = 0 # Changed only for sentinels.
at.lastLines = [] # The lines after @-leo
at.leadingWs = ""
at.root = p
at.rootSeen = False

# Stacked ivars...
at.endSentinelStack = [endLeo] # We have already handled the @+leo sentinel.
at.out = [] ; at.outStack = []
at.t = p.v.t ; at.tStack = []
at.lastThinNode = p.v ; at.thinNodeStack = [p.v]

if 0: # Useful for debugging.
    if hasattr(p.v.t,"tnodeList"):
        g.trace("len(tnodeList)",len(p.v.t.tnodeList),p.v)
    else:
        g.trace("no tnodeList",p.v)
        
# g.trace(at.startSentinelComment)</t>
<t tx="ekr.20031218072017.2760">assert(at.endSentinelStack)

at.readError(
    "Unexpected end of file. Expecting %s sentinel" %
    at.sentinelName(at.endSentinelStack[-1]))</t>
<t tx="ekr.20031218072017.2761">def readNormalLine (self,s,i):

    at = self
    
    if at.inCode:
        if not at.raw:
            s = g.removeLeadingWhitespace(s,at.indent,at.tab_width)
        at.out.append(s)
    else:
        &lt;&lt; Skip the leading stuff &gt;&gt;
        &lt;&lt; Append s to docOut &gt;&gt;</t>
<t tx="ekr.20031218072017.2762">if len(at.endSentinelComment) == 0:
    # Skip the single comment delim and a blank.
    i = g.skip_ws(s,0)
    if g.match(s,i,at.startSentinelComment):
        i += len(at.startSentinelComment)
        if g.match(s,i," "): i += 1
else:
    i = at.skipIndent(s,0,at.indent)

</t>
<t tx="ekr.20031218072017.2763">line = s[i:-1] # remove newline for rstrip.

if line == line.rstrip():
    # no trailing whitespace: the newline is real.
    at.docOut.append(line + '\n')
else:
    # trailing whitespace: the newline is fake.
    at.docOut.append(line)</t>
<t tx="ekr.20031218072017.2764"></t>
<t tx="ekr.20031218072017.2765">def readStartLeo (self,s,i):
    
    """Read an unexpected @+leo sentinel."""

    at = self
    assert(g.match(s,i,"+leo"))
    at.readError("Ignoring unexpected @+leo sentinel")</t>
<t tx="ekr.20031218072017.2766">def readStartNode (self,s,i,middle=False):
    
    """Read an @+node or @+middle sentinel."""
    
    at = self
    if middle:
        assert(g.match(s,i,"+middle:"))
        i += 8
    else:
        assert(g.match(s,i,"+node:"))
        i += 6
    
    if at.thinFile:
        &lt;&lt; set gnx and bump i &gt;&gt;
    &lt;&lt; Set headline, undoing the CWEB hack &gt;&gt;
    if not at.root_seen:
        at.root_seen = True
        &lt;&lt; Check the filename in the sentinel &gt;&gt;

    i,newIndent = g.skip_leading_ws_with_indent(s,0,at.tab_width)
    at.indentStack.append(at.indent) ; at.indent = newIndent
    
    at.outStack.append(at.out) ; at.out = []
    at.tStack.append(at.t)

    if at.importing:
        p = at.createImportedNode(at.root,at.c,headline)
        at.t = p.v.t
    elif at.thinFile:
        at.thinNodeStack.append(at.lastThinNode)
        at.lastThinNode = v = at.createThinChild(gnx,headline)
        at.t = v.t
    else:
        at.t = at.findChild(headline)
    
    at.endSentinelStack.append(endNode)</t>
<t tx="ekr.20031218072017.2767"># Set headline to the rest of the line.
# Don't strip leading whitespace."

if len(at.endSentinelComment) == 0:
    headline = s[i:-1].rstrip()
else:
    k = s.rfind(at.endSentinelComment,i)
    headline = s[i:k].rstrip() # works if k == -1

# Undo the CWEB hack: undouble @ signs if the opening comment delim ends in '@'.
if at.startSentinelComment[-1:] == '@':
    headline = headline.replace('@@','@')</t>
<t tx="ekr.20031218072017.2768">if 0: # This doesn't work so well in cooperative environments.
    if not at.importing:

        h = headline.strip()
        
        if h[:5] == "@file":
            i,junk,junk = g.scanAtFileOptions(h)
            fileName = string.strip(h[i:])
            if fileName != at.targetFileName:
                at.readError("File name in @node sentinel does not match file's name")
        elif h[:8] == "@rawfile":
            fileName = string.strip(h[8:])
            if fileName != at.targetFileName:
                at.readError("File name in @node sentinel does not match file's name")
        else:
            at.readError("Missing @file in root @node sentinel")</t>
<t tx="ekr.20031218072017.2769">def readStartOthers (self,s,i):
    
    """Read an @+others sentinel."""

    at = self
    j = g.skip_ws(s,i)
    leadingWs = s[i:j]
    if leadingWs:
        assert(g.match(s,j,"@+others"))
    else:
        assert(g.match(s,j,"+others"))

    # Make sure that the generated at-others is properly indented.
    at.out.append(leadingWs + "@others\n")
    
    at.endSentinelStack.append(endOthers)</t>
<t tx="ekr.20031218072017.2770"></t>
<t tx="ekr.20031218072017.2771">def readEndLeo (self,s,i):
    
    """Read an @-leo sentinel."""
    
    at = self

    # Ignore everything after @-leo.
    # Such lines were presumably written by @last.
    while 1:
        s = at.readLine(at.file)
        if len(s) == 0: break
        at.lastLines.append(s) # Capture all trailing lines, even if empty.

    at.done = True</t>
<t tx="ekr.20031218072017.2772">def readEndNode (self,s,i,middle=False):
    
    """Handle end-of-node processing for @-others and @-ref sentinels."""

    at = self
    
    # End raw mode.
    at.raw = False
    
    # Set the temporary body text.
    s = ''.join(at.out)
    s = g.toUnicode(s,g.app.tkEncoding) # 9/28/03

    if at.importing:
        at.t.bodyString = s
    elif middle: 
        pass # Middle sentinels never alter text.
    else:
        if hasattr(at.t,"tempBodyString") and s != at.t.tempBodyString:
            old = at.t.tempBodyString
        elif at.t.hasBody() and s != at.t.getBody():
            old = at.t.getBody()
        else:
            old = None
        if old:
            if at.perfectImportRoot:
                &lt;&lt; bump at.correctedLines and tell about the correction &gt;&gt;
                p.setMarked()
                at.t.bodyString = s # Just etting at.t.tempBodyString won't work here.
                at.t.setDirty() # Mark the node dirty.  Ancestors will be marked dirty later.
                at.c.setChanged(True)
            else:
                g.es("Warning: updating cloned text",color="blue")
                #g.es("old...\n%s\n" % old)
                #g.es("new...\n%s\n" % s)
                at.t.setDirty() # Mark the node dirty.  Ancestors will be marked dirty later.
                at.c.setChanged(True)
        at.t.tempBodyString = s

    # Indicate that the tnode has been set in the derived file.
    at.t.setVisited()

    # End the previous node sentinel.
    at.indent = at.indentStack.pop()
    at.out = at.outStack.pop()
    at.t = at.tStack.pop()
    if at.thinFile and not at.importing:
        at.lastThinNode = at.thinNodeStack.pop()

    at.popSentinelStack(endNode)</t>
<t tx="ekr.20031218072017.2773">def readEndOthers (self,s,i):
    
    """Read an @-others sentinel."""
    
    at = self
    at.popSentinelStack(endOthers)</t>
<t tx="ekr.20031218072017.2774"></t>
<t tx="ekr.20031218072017.2775">def  ignoreOldSentinel (self,s,i):
    
    """Ignore an 3.x sentinel."""
    
    g.es("Ignoring 3.x sentinel: " + s.strip(), color="blue")</t>
<t tx="ekr.20031218072017.2776">def  readAfterRef (self,s,i):
    
    """Read an @afterref sentinel."""
    
    at = self
    assert(g.match(s,i,"afterref"))
    
    # Append the next line to the text.
    s = at.readLine(at.file)
    at.out.append(s)</t>
<t tx="ekr.20031218072017.2777">def readComment (self,s,i):
    
    """Read an @comment sentinel."""

    assert(g.match(s,i,"comment"))

    # Just ignore the comment line!
</t>
<t tx="ekr.20031218072017.2778">def readDelims (self,s,i):
    
    """Read an @delims sentinel."""
    
    at = self
    assert(g.match(s,i-1,"@delims"));

    # Skip the keyword and whitespace.
    i0 = i-1
    i = g.skip_ws(s,i-1+7)
        
    # Get the first delim.
    j = i
    while i &lt; len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
        i += 1
    
    if j &lt; i:
        at.startSentinelComment = s[j:i]
        # print "delim1:", at.startSentinelComment
    
        # Get the optional second delim.
        j = i = g.skip_ws(s,i)
        while i &lt; len(s) and not g.is_ws(s[i]) and not g.is_nl(s,i):
            i += 1
        end = g.choose(j&lt;i,s[j:i],"")
        i2 = g.skip_ws(s,i)
        if end == at.endSentinelComment and (i2 &gt;= len(s) or g.is_nl(s,i2)):
            at.endSentinelComment = "" # Not really two params.
            line = s[i0:j]
            line = line.rstrip()
            at.out.append(line+'\n')
        else:
            at.endSentinelComment = end
            # print "delim2:",end
            line = s[i0:i]
            line = line.rstrip()
            at.out.append(line+'\n')
    else:
        at.readError("Bad @delims")
        # Append the bad @delims line to the body text.
        at.out.append("@delims")</t>
<t tx="ekr.20031218072017.2779">def readDirective (self,s,i):
    
    """Read an @@sentinel."""
    
    at = self
    assert(g.match(s,i,"@")) # The first '@' has already been eaten.
    
    if g.match_word(s,i,"@raw"):
        at.raw = True
    elif g.match_word(s,i,"@end_raw"):
        at.raw = False
    
    e = at.endSentinelComment
    s2 = s[i:]
    if len(e) &gt; 0:
        k = s.rfind(e,i)
        if k != -1:
            s2 = s[i:k] + '\n'
        
    start = at.startSentinelComment
    if start and len(start) &gt; 0 and start[-1] == '@':
        s2 = s2.replace('@@','@')
        
    if g.match_word(s,i,"@language"):
        &lt;&lt; handle @language &gt;&gt;
    elif g.match_word(s,i,"@comment"):
        &lt;&lt; handle @comment &gt;&gt;

    at.out.append(s2)</t>
<t tx="ekr.20031218072017.2780">def readNl (self,s,i):
    
    """Handle an @nonl sentinel."""
    
    at = self
    assert(g.match(s,i,"nl"))
    
    if at.inCode:
        at.out.append('\n')
    else:
        at.docOut.append('\n')</t>
<t tx="ekr.20031218072017.2781">def readNonl (self,s,i):
    
    """Handle an @nonl sentinel."""
    
    at = self
    assert(g.match(s,i,"nonl"))
    
    if at.inCode:
        s = ''.join(at.out)
        if s and s[-1] == '\n':
            at.out = [s[:-1]]
        else:
            g.trace("out:",s)
            at.readError("unexpected @nonl directive in code part")	
    else:
        s = ''.join(at.pending)
        if s:
            if s and s[-1] == '\n':
                at.pending = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in pending doc part")
        else:
            s = ''.join(at.docOut)
            if s and s[-1] == '\n':
                at.docOut = [s[:-1]]
            else:
                g.trace("docOut:",s)
                at.readError("unexpected @nonl directive in doc part")</t>
<t tx="ekr.20031218072017.2782">@ The sentinel contains an @ followed by a section name in angle brackets.  This code is different from the code for the @@ sentinel: the expansion of the reference does not include a trailing newline.
@c

def readRef (self,s,i):
    
    """Handle an @&lt;&lt; sentinel."""
    
    at = self
    j = g.skip_ws(s,i)
    assert(g.match(s,j,"&lt;&lt;"))
    
    if len(at.endSentinelComment) == 0:
        line = s[i:-1] # No trailing newline
    else:
        k = s.find(at.endSentinelComment,i)
        line = s[i:k] # No trailing newline, whatever k is.
            
    # Undo the cweb hack.
    start = at.startSentinelComment
    if start and len(start) &gt; 0 and start[-1] == '@':
        line = line.replace('@@','@')

    at.out.append(line)
</t>
<t tx="ekr.20031218072017.2783">def readVerbatim (self,s,i):
    
    """Read an @verbatim sentinel."""
    
    at = self
    assert(g.match(s,i,"verbatim"))
    
    # Append the next line to the text.
    s = at.readLine(at.file) 
    i = at.skipIndent(s,0,at.indent)
    at.out.append(s[i:])</t>
<t tx="ekr.20031218072017.2784">def badEndSentinel (self,expectedKind):
    
    """Handle a mismatched ending sentinel."""

    at = self
    assert(at.endSentinelStack)
    at.readError("Ignoring %s sentinel.  Expecting %s" %
        (at.sentinelName(at.endSentinelStack[-1]),
         at.sentinelName(expectedKind)))
         
def popSentinelStack (self,expectedKind):
    
    """Pop an entry from endSentinelStack and check it."""
    
    at = self
    if at.endSentinelStack and at.endSentinelStack[-1] == expectedKind:
        at.endSentinelStack.pop()
    else:
        at.badEndSentinel(expectedKind)</t>
<t tx="ekr.20031218072017.3212">def importFilesCommand (self,files,treeType,
    perfectImport=True,testing=False,verbose=False):

    c = self.c
    if c == None: return
    v = current = c.currentVnode()
    if current == None: return
    if len(files) &lt; 1: return
    self.treeType = treeType
    c.beginUpdate()
    if 1: # range of update...
        if len(files) == 2:
            &lt;&lt; Create a parent for two files having a common prefix &gt;&gt;
        for fileName in files:
            v = self.createOutline(fileName,current)
            if v: # createOutline may fail.
                if perfectImport and treeType == "@file": # Can't correct @root trees.
                    self.perfectImport(fileName,v,testing=testing,verbose=verbose)
                else:
                    g.es("imported " + fileName,color="blue")
                v.contract()
                v.setDirty()
                c.setChanged(True)
        c.validateOutline()
        current.expand()
    c.endUpdate()
    c.selectVnode(current)</t>
<t tx="ekr.20031218072017.3213">@ The two filenames have a common prefix everything before the last period is the same.  For example, x.h and x.cpp.
@c

name0 = files[0]
name1 = files[1]
prefix0, junk = g.os_path_splitext(name0)
prefix1, junk = g.os_path_splitext(name1)
if len(prefix0) &gt; 0 and prefix0 == prefix1:
    current = current.insertAsLastChild()
    junk, nameExt = g.os_path_split(prefix1)
    name,ext = g.os_path_splitext(prefix1)
    current.initHeadString(name)</t>
<t tx="ekr.20031218072017.3625"></t>
<t tx="ekr.20031218072017.3821"></t>
<t tx="ekr.20040321064134.5">def createThinChild (self,gnxString,headline):

    """Find or create a new vnode whose parent is at.lastThinNode."""

    at = self ; v = at.root.v ; c = at.c ; indices = g.app.nodeIndices
    last = at.lastThinNode ; lastIndex = last.t.fileIndex
    gnx = indices.scanGnx(gnxString,0)
    #g.trace("last",last,last.t.fileIndex)
    #g.trace("args",indices.areEqual(gnx,last.t.fileIndex),gnxString,headline)
    
    # See if there is already a child with the proper index.
    child = at.lastThinNode.firstChild()
    while child and not indices.areEqual(gnx,child.t.fileIndex):
        child = child.next()

    if at.cloneSibCount &gt; 1:
        n = at.cloneSibCount ; at.cloneSibCount = 0
        if child: clonedSibs,junk = at.scanForClonedSibs(child)
        else: clonedSibs = 0
        copies = n - clonedSibs
        # g.trace(copies,headline)
    else:
        if indices.areEqual(gnx,lastIndex):
            return last
        if child:
            return child
        copies = 1 # Create exactly one copy.

    while copies &gt; 0:
        copies -= 1
        # Create the tnode only if it does not already exist.
        tnodesDict = c.fileCommands.tnodesDict
        t = tnodesDict.get(gnxString)
        if t:
            assert(indices.areEqual(t.fileIndex,gnx))
        else:
            t = leoNodes.tnode(bodyString=None,headString=headline)
            t.fileIndex = gnx
            tnodesDict[gnxString] = t
        parent = at.lastThinNode
        child = leoNodes.vnode(c,t)
        t.vnodeList.append(child)
        child.linkAsNthChild(parent,parent.numberOfChildren())
        # g.trace("creating node",child,gnx)

    return child</t>
<t tx="ekr.20040321065415">def findNodeInTree(p,headline):

    """Search for a node in v's tree matching the given headline."""
    
    c = p.c
    for p in p.subtree_iter():
        if p.headString().strip() == headline.strip():
            return p.copy()
    return c.nullPosition()

def findNodeAnywhere(headline):
    
    c = g.top()
    for p in c.allNodes_iter():
        if p.headString().strip() == headline.strip():
            return p.copy()
    return c.nullPosition()
    
def findTopLevelNode(headline):
    
    c = g.top()
    for p in c.rootPosition().self_and_siblings_iter():
        if p.headString().strip() == headline.strip():
            return p.copy()
    return c.nullPosition()</t>
<t tx="ekr.20040327103735.2"></t>
<t tx="ekr.20040331083824.1"># Note: we could use StringIo for this.

class fileLikeObject:

    """Define a file-like object for redirecting writes to a string.
    
    The caller is responsible for handling newlines correctly."""

    def __init__(self):
        self.list = []
        self.ptr = 0

    def clear (self):   self.list = []

    def close (self): pass
    def flush (self): pass

    def get (self):
        return ''.join(self.list)
        
    def readline(self): # New for read-from-string (readOpenFile).
        if self.ptr &lt; len(self.list):
            line = self.list[self.ptr]
            # g.trace(repr(line))
            self.ptr += 1
            return line
        else: return ""

    def write (self,s):
        if s: self.list.append(s)</t>
<t tx="ekr.20040629121554">def getBuildNumber(self):
    c = self
    return c.ver[10:-1] # Strip off "(dollar)Revision" and the trailing "$"</t>
<t tx="ekr.20040629121554.1">def getSignOnLine (self):
    c = self
    return "Leo 4.2 beta 2, build %s, July 5, 2004" % c.getBuildNumber()
</t>
<t tx="ekr.20040629121554.2">def initVersion (self):
    c = self
    c.ver = "$Revision: 1.139 $" # CVS updates this.</t>
<t tx="ekr.20040629121554.3">def signOnWithVersion (self):

    c = self
    color = g.app.config.getWindowPref("log_error_color")
    signon = c.getSignOnLine()
    n1,n2,n3,junk,junk=sys.version_info
    tkLevel = c.frame.top.getvar("tk_patchLevel")
    
    g.es("Leo Log Window...",color=color)
    g.es(signon)
    g.es("Python %d.%d.%d, Tk %s, %s" % (n1,n2,n3,tkLevel,sys.platform))
    g.enl()</t>
<t tx="ekr.20040716061450">if headline.strip() == v.headString().strip():
    t.setVisited() # Supress warning about unvisited node.
    return t
else:
    at.readError(
        "Mismatched headline.\nExpecting: %s\ngot: %s" %
        (headline,v.headString()))
    g.trace("Mismatched headline",headline,v.headString())
    g.trace(at.tnodeListIndex,len(at.root.v.t.tnodeList))
    return None</t>
<t tx="ekr.20040716064333">nodeIndices = g.app.nodeIndices

nodeIndices.setTimestamp()

for p2 in root.self_and_subtree_iter():
    try: # Will fail for None or any pre 4.1 file index.
        id,time,n = p2.v.t.fileIndex
    except TypeError:
        p2.v.t.fileIndex = nodeIndices.getNewIndex()</t>
<t tx="ekr.20040716064333.1">df.write(root,thinFile=True,toString=True)
s = df.stringOutput
if not s: return
</t>
<t tx="ekr.20040716065356">for p2 in p.self_and_subtree_iter():
    p2.clearDirty()</t>
<t tx="ekr.20040716105102">i = last_nosent_i

if i + 1 &lt; len(lines):
    
    # The mu.marker probably ends in '@'
    if marker[-1] == '@': marker = marker[:-1]

    line = lines[i+1]
    j = g.skip_ws(line,0)

    if match(line,j,marker):
        j += len(marker)

        if g.match(line,j,"@nonl"):
            line = lines[i]
            if line[-1] == '\n':
                assert(result[-1] == line)
                result[-1] = line[:-1]</t>
<t tx="ekr.20040716105102.1"></t>
<t tx="ekr.20040717112739">@nocolor
@

This algorithm corrects the result of an Import To @file command so that it is guaranteed that the result of writing the imported file will be identical to the original file except for any sentinels that have been inserted.

On entry, p points to the newly imported outline.

We correct the outline by applying Bernhard Mulder's algorithm.

1.  We use the atFile.write code to write the newly imported outline to a string s.  This string contains represents a thin derived file, so it can be used to recreate then entire outline structure without any other information.

Splitting s into lines creates the fat_lines argument to mu methods.

2. We make corrections to fat_lines using Mulder's algorithm.  The corrected fat_lines represents the corrected outline.  To do this, we set the arguments as follows:

- i_lines: fat_lines stripped of sentinels
- j_lines to the lines of the original imported file.

The algorithm updates fat_lines using diffs between i_lines and j_lines.

3. Mulder's algorithm doesn't specify which nodes have been changed.  In fact, it Mulder's algorithm doesn't really understand nodes at all.  Therefore, if we want to mark changed nodes we do so by comparing the original version of the imported outline with the corrected version of the outline.</t>
<t tx="ekr.20040717113036">@ Notes:
1. This code must overwrite the newly-imported tree because the gnx's in
write_lines refer to those nodes.

2. The code in readEndNode now reports when nodes change during importing. This
code also marks changed nodes.
@c

try:
    df.correctedLines = 0
    df.targetFileName = "&lt;perfectImport string-file&gt;"
    df.inputFile = fo = g.fileLikeObject()
    df.file = fo # Strange, that this is needed.  Should be cleaned up.
    for line in write_lines:
        fo.write(line)
    firstLines,junk = c.atFileCommands.scanHeader(fo,df.targetFileName)
    # To do: pass params to readEndNode.
    df.readOpenFile(root,fo,firstLines,perfectImportRoot=root)
    n = df.correctedLines
    if verbose:
        g.es("%d marked node%s corrected" % (n,g.choose(n==1,'','s')),color="blue")
except:
    g.es("Exception in Perfect Import",color="red")
    g.es_exception()
    s = None</t>
<t tx="ekr.20040717132539">write_lines_node = root.insertAfter()
write_lines_node.initHeadString("write_lines")
s = ''.join(write_lines)
write_lines_node.scriptSetBodyString(s,encoding=g.app.tkEncoding)</t>
<t tx="ekr.20040717133553">@killcolor

- Added readline method to fileLikeObject class: new_df.readOpenFile calls readline.

- Added perfectImportRoot keyword arg to new_df.readOpenFile.

- Added perfectImportRoot ivar to new_df class.

- readEndNode counts the number of corrected nodes, and marks all corrected nodes.

- Forced at.perfectImportRoot = False in top-level read code.
    This corrects a problem with reading LeoDocs.leo during unit tests.</t>
<t tx="ekr.20040717133944"># Report the number of corrected nodes.
at.correctedLines += 1

found = False
for p in at.perfectImportRoot.self_and_subtree_iter():
    if p.v.t == at.t:
        found = True ; break

if found:
    if 0: # Not needed: we mark all corrected nodes.
        g.es("Correcting %s" % p.headString(),color="blue")
    if 0: # For debugging.
        print ; print '-' * 40
        print "old",len(old)
        for line in g.splitLines(old):
            #line = line.replace(' ','&lt; &gt;').replace('\t','&lt;TAB&gt;')
            print repr(str(line))
        print ; print '-' * 40
        print "new",len(s)
        for line in g.splitLines(s):
            #line = line.replace(' ','&lt; &gt;').replace('\t','&lt;TAB&gt;')
            print repr(str(line))
        print ; print '-' * 40
else:
    # This should never happen.
    g.es("Correcting hidden node: t=%s" % repr(at.t),color="red")</t>
<t tx="ekr.20040718035658">try:
    # Read the original file into before_lines.
    before = file(fileName)
    before_lines = before.readlines()
    before.close()
    
    # Write the tree into after_lines.
    df.write(root,thinFile=True,toString=True)
    after_lines1 = g.splitLines(df.stringOutput)
    
    # Strip sentinels from after_lines and compare.
    after_lines = mu.removeSentinelsFromLines(after_lines1,marker)
    
    # A major kludge: Leo can not represent unindented blank lines in indented nodes!
    # We ignore the problem here by stripping whitespace from blank lines.
    # We shall need output options to handle such lines.
    if convertBlankLines:
        mu.stripWhitespaceFromBlankLines(before_lines)
        mu.stripWhitespaceFromBlankLines(after_lines)
    if before_lines == after_lines:
        if verbose:
            g.es("Perfect Import verified",color="blue")
    else:
        leoTest.fail()
        if verbose:
            g.es("Perfect Import failed verification test!",color="red")
            &lt;&lt; dump the files &gt;&gt;
except IOError:
    g.es("Can not reopen %s!" % fileName,color="red")
    leoTest.fail()</t>
<t tx="ekr.20040718042049"></t>
<t tx="ekr.20040718042049.1"></t>
<t tx="ekr.20040718045423">print len(before_lines),len(after_lines)

if len(before_lines)==len(after_lines):
    for i in xrange(len(before_lines)):
        extra = 3
        if before_lines[i] != after_lines[i]:
            j = max(0,i-extra)
            print '-' * 20
            while j &lt; i + extra + 1:
                leader = g.choose(i == j,"* ","  ")
                print "%s%3d" % (leader,j), repr(before_lines[j])
                print "%s%3d" % (leader,j), repr(after_lines[j])
                j += 1
else:
    for i in xrange(min(len(before_lines),len(after_lines))):
        if before_lines[i] != after_lines[i]:
            extra = 3
            print "first mismatch at line %d" % i
            print "printing %d lines after mismatch"
            print "before..."
            for j in xrange(i+1+extra):
                print "%3d" % j, repr(before_lines[j])
            print
            print "after..."
            for k in xrange(1+extra):
                print "%3d" % (i+k), repr(after_lines[i+k])
            print
            print "with sentinels"
            j = 0 ; k = 0
            while k &lt; i + 1 + extra:
                print "%3d" % k,repr(after_lines1[j])
                if not mu.is_sentinel(after_lines1[j],marker):
                    k += 1
                j += 1
            break</t>
<t tx="ekr.20040718050922">@nocolor

Leo can't represent some files using nodes!

I call this the "unindented blank line" problem.

Example:

@color

class aClass:
    def spam(): pass
# comment line
    def eggs(): pass
    
@nocolor

Leo's import code can't handle this:
    
- If the import code putsthe comment line in a node, the line won't be output with the proper indentation!!

- Having the comment line stop the scanning of aClass is even worse.

- This usually shows up with an unindented blank line instead of the comment line.</t>
<t tx="ekr.20040718101315">def stripWhitespaceFromBlankLines (self,lines):
    
    # All backslashes must be doubled.

    """Strip blanks and tabs from lines containing only blanks and tabs.
    
    &gt;&gt;&gt; import leoGlobals as g
    &gt;&gt;&gt; s = "a\\n \\t\\n\\t\\t \\t\\nb"
    &gt;&gt;&gt; theLines = g.splitLines(s)
    &gt;&gt;&gt; theLines
    ['a\\n', ' \\t\\n', '\\t\\t \\t\\n', 'b']
    &gt;&gt;&gt; g.mulderUpdateAlgorithm().stripWhitespaceFromBlankLines(theLines)
    ['a\\n', '\\n', '\\n', 'b']
    """

    for i in xrange(len(lines)):
        stripped_line = lines[i].lstrip(" \t")
        if stripped_line in ('\n',''):
            lines[i] = stripped_line
            
    return lines</t>
</tnodes>
</leo_file>
